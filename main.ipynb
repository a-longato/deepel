{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20d368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/endriu/Desktop/deepel/venv/lib/python3.13/site-packages/deepproblog/engines/__init__.py:6: UserWarning: ApproximateEngine is not available as PySwip could not be found\n",
      "  warnings.warn(\"ApproximateEngine is not available as PySwip could not be found\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from deepproblog.dataset import DataLoader\n",
    "from deepproblog.engines import ExactEngine\n",
    "from deepproblog.model import Model\n",
    "from deepproblog.network import Network\n",
    "from deepproblog.train import train_model\n",
    "from data_manager import loading_abstraction_extended, BinaryTargetDataset, BinaryTargetInterface, AnimalCategorizer\n",
    "from neural import OptimizedMLP\n",
    "from conf_matrix import get_confusion_matrix_and_errors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbc7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT_RATIO = 0.2\n",
    "RANDOM_SEED = 42\n",
    "#NUM_ATTRIBUTES = 48\n",
    "DATA_PATH = 'Animals_with_Attributes2/ResNet101/AwA2-features.txt'\n",
    "LABEL_PATH = 'Animals_with_Attributes2/ResNet101/AwA2-labels.txt'\n",
    "BINARY_TARGET_PATH = 'Animals_with_Attributes2/predicate-matrix-binary.txt'\n",
    "\n",
    "QUERY_NAMES = ['is_terrestrial', 'is_aquatic', 'is_ungulate', 'is_carnivore']\n",
    "INDICES = [[32,42],[10,11,27,43],[18,22,32,35,42],[33,34,37]]\n",
    "QUERY_TO_INDICES = {\n",
    "    'is_terrestrial': INDICES[0],\n",
    "    'is_aquatic': INDICES[1],\n",
    "    'is_ungulate' : INDICES[2],\n",
    "    'is_carnivore' : INDICES[3]\n",
    "}\n",
    "KB_FILENAMES = ['knowledge_bases/kb_terr_test.pl', 'knowledge_bases/kb_aqua_test.pl',\n",
    "                'knowledge_bases/kb_ungulates.pl', 'knowledge_bases/kb_carnivore.pl']\n",
    "QUERY_TO_KB = {\n",
    "    'is_terrestrial': KB_FILENAMES[0],\n",
    "    'is_aquatic': KB_FILENAMES[1],\n",
    "    'is_ungulate' : KB_FILENAMES[2],\n",
    "    'is_carnivore' : KB_FILENAMES[3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bee348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37322\n"
     ]
    }
   ],
   "source": [
    "#indices = [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 39, 42, 44, 45, 51, 52, 54, 55, 58, 59, 64, 66, 68, 74, 75, 76, 78, 80, 84]\n",
    "indices_to_extract = sorted([item for sublist in INDICES for item in sublist])\n",
    "data, label_indices, binary_vectors = loading_abstraction_extended(DATA_PATH, LABEL_PATH, BINARY_TARGET_PATH,\n",
    "                                                                   attribute_indices_to_extract=indices_to_extract)\n",
    "print(len(label_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6979d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_terrestrial = [2,8,16,17,23,29,35,46,49]\n",
    "terrestrial_labels = [1 if label not in non_terrestrial else 0 for label in label_indices]\n",
    "\n",
    "aquatic = [2,3,8,13,17,23,35,44,46,49]\n",
    "hairless_aquatic = [2,8,13,17,23,46,49]\n",
    "furry_aquatic = [3,35,44]\n",
    "aquatic_labels = [2 if label in furry_aquatic else 1 if label in hairless_aquatic else 0 for label in label_indices]\n",
    "\n",
    "unhorned_ungulates = [6,22,37,41]\n",
    "horned_ungulates = [0,15,20,27,30,36,39,48]\n",
    "ungulate_labels = [2 if label in horned_ungulates else 1 if label in unhorned_ungulates else 0 for label in label_indices]\n",
    "\n",
    "carnivores = [1,2,7,9,12,14,21,23,29,31,33,34,35,40,42,44,45]\n",
    "carnivore_labels = [1 if label in carnivores else 0 for label in label_indices]\n",
    "\n",
    "QUERY_TO_LABELS = {\n",
    "    'is_terrestrial': terrestrial_labels,\n",
    "    'is_aquatic': aquatic_labels,\n",
    "    'is_ungulate': ungulate_labels,\n",
    "    'is_carnivore': carnivore_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a62bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 29857, Testing samples: 7465\n"
     ]
    }
   ],
   "source": [
    "original_sample_indices = list(range(len(label_indices)))\n",
    "train_indices, test_indices = train_test_split(\n",
    "    original_sample_indices,\n",
    "    test_size=TEST_SPLIT_RATIO,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=[label_indices[i] for i in original_sample_indices]\n",
    ")\n",
    "print(f\"Training samples: {len(train_indices)}, Testing samples: {len(test_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518bcff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set distribution: Counter({6: 329, 22: 284, 39: 269, 48: 268, 26: 240, 30: 240, 37: 234, 28: 218, 0: 209, 18: 208, 7: 207, 45: 206, 42: 204, 23: 198, 49: 189, 36: 179, 12: 175, 38: 175, 19: 174, 44: 174, 1: 170, 25: 156, 35: 152, 5: 149, 20: 146, 24: 146, 14: 144, 41: 143, 17: 142, 15: 141, 27: 139, 13: 137, 21: 133, 40: 126, 31: 118, 32: 113, 4: 110, 47: 102, 9: 100, 29: 76, 33: 62, 16: 58, 2: 58, 34: 54, 46: 43, 3: 38, 10: 37, 43: 37, 8: 35, 11: 20})\n"
     ]
    }
   ],
   "source": [
    "test_distribution = [label_indices[i] for i in test_indices]\n",
    "print(f'Test set distribution: {Counter(test_distribution)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9fa7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching ACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/endriu/Desktop/deepel/venv/lib/python3.13/site-packages/deepproblog/semiring/graph_semiring.py:77: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  return -self.eps <= float(a) <= self.eps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         \t \t    \tActual\t   \n",
      "         \t \t   0\t     2\t  1\n",
      "Predicted\t0\t4863\t    55\t 40\n",
      "         \t2\t   9\t  1500\t 16\n",
      "         \t1\t  12\t    36\t934\n",
      "Accuracy:  0.9774949765572672\n",
      "Accuracy 0.9774949765572672\n",
      "Counter({15: 25, 48: 25, 41: 23, 6: 20, 36: 13, 27: 12, 22: 10, 39: 8, 1: 5, 13: 5, 0: 5, 18: 4, 37: 3, 30: 2, 19: 1, 7: 1, 40: 1, 45: 1, 42: 1, 31: 1, 20: 1, 28: 1})\n"
     ]
    }
   ],
   "source": [
    "for query in QUERY_NAMES[2:3]:\n",
    "    labels = QUERY_TO_LABELS[query]\n",
    "    dataset = BinaryTargetDataset(data, labels, binary_vectors) # here change labels\n",
    "    # We pass full dataset to the interface\n",
    "    interface = BinaryTargetInterface(dataset)\n",
    "\n",
    "    # Create datasets using the full dataset but with specific sample indices\n",
    "    # HERE CHANGE FUNCTION\n",
    "    train_set = AnimalCategorizer(\n",
    "        dataset_name=dataset,  # Pass the full dataset\n",
    "        function_name=query,\n",
    "        seed=42,\n",
    "        sample_indices=train_indices  # Pass only the sample indices you want\n",
    "    )\n",
    "    test_set = AnimalCategorizer(\n",
    "        dataset_name=dataset,\n",
    "        function_name=query,\n",
    "        seed=42,\n",
    "        sample_indices=test_indices\n",
    "    )\n",
    "\n",
    "    networks = {}\n",
    "    for i in QUERY_TO_INDICES[query]:\n",
    "        network = OptimizedMLP()\n",
    "        network.load_state_dict(torch.load(f'pretrained_mlps/net{i}.pth', map_location=torch.device('cpu')))\n",
    "        net = Network(network, f\"net{i}\", batching=True)\n",
    "        net.optimizer = torch.optim.AdamW(network.parameters(), lr=1e-4)\n",
    "        networks[f\"net{i}\"] = net\n",
    "    model = Model('knowledge_bases/kb_ungulates_updated.pl', list(networks.values()))\n",
    "    model.set_engine(ExactEngine(model), cache=True)\n",
    "    # Add tensor sources for accessing the images\n",
    "    model.add_tensor_source(\"dataset\", interface)\n",
    "    \n",
    "    _, errors_indices = get_confusion_matrix_and_errors(model, test_set, verbose=1)\n",
    "    miss_labels = [label_indices[x] for x in errors_indices]\n",
    "    print(Counter(miss_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d8920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching ACs\n",
      "Training  for 10 epoch(s)\n",
      "Epoch 1\n",
      "Iteration:  50 \ts:8.9783 \tAverage Loss:  0.7301214514904859\n",
      "Iteration:  100 \ts:7.5383 \tAverage Loss:  0.32127998276013386\n",
      "Iteration:  150 \ts:10.8749 \tAverage Loss:  0.2619075731005978\n",
      "Iteration:  200 \ts:26.8869 \tAverage Loss:  0.17706948293047844\n",
      "Iteration:  250 \ts:29.4375 \tAverage Loss:  0.14438578516799452\n",
      "Iteration:  300 \ts:29.9381 \tAverage Loss:  0.14478316725816967\n",
      "Iteration:  350 \ts:20.1766 \tAverage Loss:  0.1379188561191654\n",
      "Iteration:  400 \ts:24.4318 \tAverage Loss:  0.12316168004940892\n",
      "Iteration:  450 \ts:23.5154 \tAverage Loss:  0.12148968469966576\n",
      "Iteration:  500 \ts:14.3378 \tAverage Loss:  0.13075506510375307\n",
      "Iteration:  550 \ts:4.7991 \tAverage Loss:  0.177791486276069\n",
      "Iteration:  600 \ts:6.6518 \tAverage Loss:  0.12242058071691077\n",
      "Iteration:  650 \ts:6.5300 \tAverage Loss:  0.14307049435502905\n",
      "Iteration:  700 \ts:6.5191 \tAverage Loss:  0.11831600891825018\n",
      "Iteration:  750 \ts:6.8952 \tAverage Loss:  0.10730638166843164\n",
      "Iteration:  800 \ts:22.6632 \tAverage Loss:  0.13982562647957367\n",
      "Iteration:  850 \ts:28.4230 \tAverage Loss:  0.12004496380323872\n",
      "Iteration:  900 \ts:27.0394 \tAverage Loss:  0.1329642772726163\n",
      "Iteration:  950 \ts:27.3486 \tAverage Loss:  0.12397552485639324\n",
      "Iteration:  1000 \ts:27.7196 \tAverage Loss:  0.1018210761520129\n",
      "Iteration:  1050 \ts:28.0786 \tAverage Loss:  0.07484981916842046\n",
      "Iteration:  1100 \ts:25.4963 \tAverage Loss:  0.14487505326942596\n",
      "Iteration:  1150 \ts:24.3911 \tAverage Loss:  0.10539457255421097\n",
      "Iteration:  1200 \ts:22.9111 \tAverage Loss:  0.09533617507457563\n",
      "Epoch time:  484.6179714202881\n",
      "Epoch 2\n",
      "Iteration:  1250 \ts:25.5365 \tAverage Loss:  0.0996853760299507\n",
      "Iteration:  1300 \ts:28.0088 \tAverage Loss:  0.056380938414626484\n",
      "Iteration:  1350 \ts:28.7999 \tAverage Loss:  0.08583864151903584\n",
      "Iteration:  1400 \ts:27.2696 \tAverage Loss:  0.08611734973595389\n",
      "Iteration:  1450 \ts:28.8408 \tAverage Loss:  0.08062989750656598\n",
      "Iteration:  1500 \ts:27.2793 \tAverage Loss:  0.07965210533964295\n",
      "Iteration:  1550 \ts:23.7717 \tAverage Loss:  0.08837823518113623\n",
      "Iteration:  1600 \ts:26.8443 \tAverage Loss:  0.07402724738773828\n",
      "Iteration:  1650 \ts:26.1292 \tAverage Loss:  0.055770307291269174\n",
      "Iteration:  1700 \ts:28.3045 \tAverage Loss:  0.07198314154839537\n",
      "Iteration:  1750 \ts:25.3071 \tAverage Loss:  0.0624876093157269\n",
      "Iteration:  1800 \ts:25.6280 \tAverage Loss:  0.07013323279101825\n",
      "Iteration:  1850 \ts:15.4547 \tAverage Loss:  0.09536716839186767\n",
      "Iteration:  1900 \ts:26.4478 \tAverage Loss:  0.060440636530256595\n",
      "Iteration:  1950 \ts:26.4340 \tAverage Loss:  0.11087689235274467\n",
      "Iteration:  2000 \ts:24.2527 \tAverage Loss:  0.06337667004511616\n",
      "Iteration:  2050 \ts:26.8238 \tAverage Loss:  0.1272949592298747\n",
      "Iteration:  2100 \ts:21.3717 \tAverage Loss:  0.06225198292184515\n",
      "Iteration:  2150 \ts:19.4041 \tAverage Loss:  0.10390159606322072\n",
      "Iteration:  2200 \ts:25.9454 \tAverage Loss:  0.06111931128208767\n",
      "Iteration:  2250 \ts:25.7251 \tAverage Loss:  0.06431400353600822\n",
      "Iteration:  2300 \ts:27.9177 \tAverage Loss:  0.06265521827071126\n",
      "Iteration:  2350 \ts:27.8641 \tAverage Loss:  0.0933424931711933\n",
      "Iteration:  2400 \ts:24.1011 \tAverage Loss:  0.04230546784297786\n",
      "Iteration:  2450 \ts:27.5185 \tAverage Loss:  0.05805813412919839\n",
      "Epoch time:  637.3119015693665\n",
      "Epoch 3\n",
      "Iteration:  2500 \ts:24.3260 \tAverage Loss:  0.07063826873206196\n",
      "Iteration:  2550 \ts:22.5917 \tAverage Loss:  0.05505038652149637\n",
      "Iteration:  2600 \ts:15.5114 \tAverage Loss:  0.04224523870861305\n",
      "Iteration:  2650 \ts:23.4319 \tAverage Loss:  0.04853940941175075\n",
      "Iteration:  2700 \ts:26.3540 \tAverage Loss:  0.07618858420376838\n",
      "Iteration:  2750 \ts:26.9606 \tAverage Loss:  0.03965083361582316\n",
      "Iteration:  2800 \ts:27.5512 \tAverage Loss:  0.0682249623673787\n",
      "Iteration:  2850 \ts:19.4033 \tAverage Loss:  0.06261783543893898\n",
      "Iteration:  2900 \ts:16.4965 \tAverage Loss:  0.060007729237659645\n",
      "Iteration:  2950 \ts:15.1978 \tAverage Loss:  0.0638112200160326\n",
      "Iteration:  3000 \ts:6.2881 \tAverage Loss:  0.04509703726619065\n",
      "Iteration:  3050 \ts:12.3599 \tAverage Loss:  0.07491507536563212\n",
      "Iteration:  3100 \ts:21.0925 \tAverage Loss:  0.042720971118054084\n",
      "Iteration:  3150 \ts:25.7285 \tAverage Loss:  0.061132513739292446\n",
      "Iteration:  3200 \ts:22.8113 \tAverage Loss:  0.05242526066792721\n",
      "Iteration:  3250 \ts:23.6102 \tAverage Loss:  0.05969096574144217\n",
      "Iteration:  3300 \ts:19.7071 \tAverage Loss:  0.04774022742533248\n",
      "Iteration:  3350 \ts:22.2012 \tAverage Loss:  0.05454564092968638\n",
      "Iteration:  3400 \ts:24.0266 \tAverage Loss:  0.0640268211003545\n",
      "Iteration:  3450 \ts:24.4415 \tAverage Loss:  0.051732590490108595\n",
      "Iteration:  3500 \ts:21.8363 \tAverage Loss:  0.042515666810429946\n",
      "Iteration:  3550 \ts:25.7758 \tAverage Loss:  0.07126190321924114\n",
      "Iteration:  3600 \ts:25.2491 \tAverage Loss:  0.06243409749617981\n",
      "Iteration:  3650 \ts:23.9302 \tAverage Loss:  0.0865067067160222\n",
      "Iteration:  3700 \ts:24.9094 \tAverage Loss:  0.03394589157412391\n",
      "Epoch time:  539.5119023323059\n",
      "Epoch 4\n",
      "Iteration:  3750 \ts:19.7860 \tAverage Loss:  0.04111403869360778\n",
      "Iteration:  3800 \ts:9.0163 \tAverage Loss:  0.03789797091057835\n",
      "Iteration:  3850 \ts:7.2852 \tAverage Loss:  0.06508878347891098\n",
      "Iteration:  3900 \ts:8.1470 \tAverage Loss:  0.03949711957164595\n",
      "Iteration:  3950 \ts:7.4116 \tAverage Loss:  0.03405942854840166\n",
      "Iteration:  4000 \ts:6.0481 \tAverage Loss:  0.01789254244252902\n",
      "Iteration:  4050 \ts:6.3178 \tAverage Loss:  0.05758001748691459\n",
      "Iteration:  4100 \ts:6.0662 \tAverage Loss:  0.04311784573336702\n",
      "Iteration:  4150 \ts:5.8859 \tAverage Loss:  0.03871590703182136\n",
      "Iteration:  4200 \ts:6.0973 \tAverage Loss:  0.04577970278177641\n",
      "Iteration:  4250 \ts:6.0855 \tAverage Loss:  0.0345078696683489\n",
      "Iteration:  4300 \ts:5.9842 \tAverage Loss:  0.021998015779805157\n",
      "Iteration:  4350 \ts:7.5201 \tAverage Loss:  0.043946085610054836\n",
      "Iteration:  4400 \ts:22.6827 \tAverage Loss:  0.050278685735697624\n",
      "Iteration:  4450 \ts:22.9396 \tAverage Loss:  0.04273411787455984\n",
      "Iteration:  4500 \ts:26.1795 \tAverage Loss:  0.07209113698321197\n",
      "Iteration:  4550 \ts:22.4332 \tAverage Loss:  0.05572814734365679\n",
      "Iteration:  4600 \ts:20.4656 \tAverage Loss:  0.041175948508374846\n",
      "Iteration:  4650 \ts:25.4707 \tAverage Loss:  0.03162106720026401\n",
      "Iteration:  4700 \ts:25.9173 \tAverage Loss:  0.04470121691141436\n",
      "Iteration:  4750 \ts:23.5500 \tAverage Loss:  0.0440818716231626\n",
      "Iteration:  4800 \ts:25.0011 \tAverage Loss:  0.024493731753099723\n",
      "Iteration:  4850 \ts:25.1501 \tAverage Loss:  0.07558930544798911\n",
      "Iteration:  4900 \ts:23.7393 \tAverage Loss:  0.04949456589223558\n",
      "Iteration:  4950 \ts:24.5574 \tAverage Loss:  0.06213932217475225\n",
      "Epoch time:  388.2162640094757\n",
      "Epoch 5\n",
      "Iteration:  5000 \ts:25.0307 \tAverage Loss:  0.04620948926248644\n",
      "Iteration:  5050 \ts:22.4678 \tAverage Loss:  0.05499581942241001\n",
      "Iteration:  5100 \ts:16.8845 \tAverage Loss:  0.025819336808984517\n",
      "Iteration:  5150 \ts:16.2431 \tAverage Loss:  0.03593485343493057\n",
      "Iteration:  5200 \ts:14.6749 \tAverage Loss:  0.0320391850225926\n",
      "Iteration:  5250 \ts:17.1506 \tAverage Loss:  0.01715593177774103\n",
      "Iteration:  5300 \ts:15.2339 \tAverage Loss:  0.02530113259559137\n",
      "Iteration:  5350 \ts:7.7889 \tAverage Loss:  0.03645583586367181\n",
      "Iteration:  5400 \ts:19.1205 \tAverage Loss:  0.03167221386229148\n",
      "Iteration:  5450 \ts:16.2407 \tAverage Loss:  0.031668568728142145\n",
      "Iteration:  5500 \ts:25.4280 \tAverage Loss:  0.02675358801116051\n",
      "Iteration:  5550 \ts:23.2748 \tAverage Loss:  0.040220462502112614\n",
      "Iteration:  5600 \ts:22.1212 \tAverage Loss:  0.04113220657676919\n",
      "Iteration:  5650 \ts:23.1605 \tAverage Loss:  0.027407948197391185\n",
      "Iteration:  5700 \ts:23.5850 \tAverage Loss:  0.020812648877531537\n",
      "Iteration:  5750 \ts:24.5847 \tAverage Loss:  0.0405606058915588\n",
      "Iteration:  5800 \ts:23.3005 \tAverage Loss:  0.03101547603722551\n",
      "Iteration:  5850 \ts:24.6750 \tAverage Loss:  0.05678999321760962\n",
      "Iteration:  5900 \ts:23.0001 \tAverage Loss:  0.046769689378587526\n",
      "Iteration:  5950 \ts:20.5730 \tAverage Loss:  0.0275084613580929\n",
      "Iteration:  6000 \ts:14.2687 \tAverage Loss:  0.038800476363691064\n",
      "Iteration:  6050 \ts:21.0960 \tAverage Loss:  0.02948170181415989\n",
      "Iteration:  6100 \ts:21.2675 \tAverage Loss:  0.03338081719174284\n",
      "Iteration:  6150 \ts:18.3767 \tAverage Loss:  0.024613370551345\n",
      "Iteration:  6200 \ts:21.9508 \tAverage Loss:  0.03279619472219146\n",
      "Epoch time:  495.85564160346985\n",
      "Epoch 6\n",
      "Iteration:  6250 \ts:18.4105 \tAverage Loss:  0.031334966716081\n",
      "Iteration:  6300 \ts:20.5942 \tAverage Loss:  0.024315584574082366\n",
      "Iteration:  6350 \ts:18.8733 \tAverage Loss:  0.015951441662411872\n",
      "Iteration:  6400 \ts:14.9556 \tAverage Loss:  0.014298341625901293\n",
      "Iteration:  6450 \ts:20.0172 \tAverage Loss:  0.028059040619906633\n",
      "Iteration:  6500 \ts:14.2399 \tAverage Loss:  0.026790441547400193\n",
      "Iteration:  6550 \ts:12.1686 \tAverage Loss:  0.018461198943911263\n",
      "Iteration:  6600 \ts:14.5338 \tAverage Loss:  0.021703771912910702\n",
      "Iteration:  6650 \ts:22.7418 \tAverage Loss:  0.032246246158541075\n",
      "Iteration:  6700 \ts:8.0197 \tAverage Loss:  0.012466848347954099\n",
      "Iteration:  6750 \ts:5.7640 \tAverage Loss:  0.021522616848547678\n",
      "Iteration:  6800 \ts:12.4885 \tAverage Loss:  0.026556738927521764\n",
      "Iteration:  6850 \ts:12.8389 \tAverage Loss:  0.03494882292650537\n",
      "Iteration:  6900 \ts:12.8823 \tAverage Loss:  0.03171883415690001\n",
      "Iteration:  6950 \ts:13.4689 \tAverage Loss:  0.015222058879737653\n",
      "Iteration:  7000 \ts:13.4341 \tAverage Loss:  0.02353019552636958\n",
      "Iteration:  7050 \ts:12.9056 \tAverage Loss:  0.0182500676775766\n",
      "Iteration:  7100 \ts:12.9332 \tAverage Loss:  0.03417981956052259\n",
      "Iteration:  7150 \ts:13.7713 \tAverage Loss:  0.03206748702199448\n",
      "Iteration:  7200 \ts:13.1893 \tAverage Loss:  0.0435316146335056\n",
      "Iteration:  7250 \ts:13.2379 \tAverage Loss:  0.0501037005874316\n",
      "Iteration:  7300 \ts:13.3601 \tAverage Loss:  0.04735798210644816\n",
      "Iteration:  7350 \ts:13.8877 \tAverage Loss:  0.02073701370859766\n",
      "Iteration:  7400 \ts:12.9969 \tAverage Loss:  0.027820810399850623\n",
      "Iteration:  7450 \ts:14.2266 \tAverage Loss:  0.03169574581199605\n",
      "Epoch time:  351.1505768299103\n",
      "Epoch 7\n",
      "Iteration:  7500 \ts:12.2485 \tAverage Loss:  0.019058782838985096\n",
      "Iteration:  7550 \ts:12.4157 \tAverage Loss:  0.02211041548694588\n",
      "Iteration:  7600 \ts:12.8295 \tAverage Loss:  0.03154066564827133\n",
      "Iteration:  7650 \ts:12.8671 \tAverage Loss:  0.021900643476393745\n",
      "Iteration:  7700 \ts:13.1087 \tAverage Loss:  0.014042080345534167\n",
      "Iteration:  7750 \ts:13.2429 \tAverage Loss:  0.02356172097588434\n",
      "Iteration:  7800 \ts:13.8144 \tAverage Loss:  0.036313693189271135\n",
      "Iteration:  7850 \ts:13.2878 \tAverage Loss:  0.016447665046347596\n",
      "Iteration:  7900 \ts:12.9134 \tAverage Loss:  0.012019562207582163\n",
      "Iteration:  7950 \ts:13.0031 \tAverage Loss:  0.012661040374667466\n",
      "Iteration:  8000 \ts:13.0053 \tAverage Loss:  0.032231149563482546\n",
      "Iteration:  8050 \ts:12.9829 \tAverage Loss:  0.032147370665634084\n",
      "Iteration:  8100 \ts:13.2006 \tAverage Loss:  0.02177003107599159\n",
      "Iteration:  8150 \ts:13.8576 \tAverage Loss:  0.01444380676066519\n",
      "Iteration:  8200 \ts:12.5043 \tAverage Loss:  0.016438733811115967\n",
      "Iteration:  8250 \ts:13.0505 \tAverage Loss:  0.024574325383262662\n",
      "Iteration:  8300 \ts:12.9402 \tAverage Loss:  0.022150901975277647\n",
      "Iteration:  8350 \ts:13.1639 \tAverage Loss:  0.018815601532642886\n",
      "Iteration:  8400 \ts:13.1806 \tAverage Loss:  0.021333389318963895\n",
      "Iteration:  8450 \ts:13.0535 \tAverage Loss:  0.026716026009367334\n",
      "Iteration:  8500 \ts:12.6785 \tAverage Loss:  0.01780358527255217\n",
      "Iteration:  8550 \ts:12.7386 \tAverage Loss:  0.01333407745161427\n",
      "Iteration:  8600 \ts:12.7696 \tAverage Loss:  0.04039735010919191\n",
      "Iteration:  8650 \ts:13.0422 \tAverage Loss:  0.0261022803994517\n",
      "Iteration:  8700 \ts:13.2105 \tAverage Loss:  0.013818054505110453\n",
      "Epoch time:  324.37809014320374\n",
      "Epoch 8\n",
      "Iteration:  8750 \ts:13.4477 \tAverage Loss:  0.013934089925941322\n",
      "Iteration:  8800 \ts:12.2315 \tAverage Loss:  0.012698589292311767\n",
      "Iteration:  8850 \ts:13.0022 \tAverage Loss:  0.020984145481858008\n",
      "Iteration:  8900 \ts:12.9434 \tAverage Loss:  0.0126443745800783\n",
      "Iteration:  8950 \ts:14.6192 \tAverage Loss:  0.016847179452610737\n",
      "Iteration:  9000 \ts:15.1485 \tAverage Loss:  0.014925347570390208\n",
      "Iteration:  9050 \ts:10.4100 \tAverage Loss:  0.012958525065958959\n",
      "Iteration:  9100 \ts:12.3564 \tAverage Loss:  0.015788913672573485\n",
      "Iteration:  9150 \ts:12.6178 \tAverage Loss:  0.01331543997947776\n",
      "Iteration:  9200 \ts:13.6900 \tAverage Loss:  0.014273787279478896\n",
      "Iteration:  9250 \ts:12.4651 \tAverage Loss:  0.013540863664604146\n",
      "Iteration:  9300 \ts:12.1835 \tAverage Loss:  0.016039096273181456\n",
      "Iteration:  9350 \ts:12.3939 \tAverage Loss:  0.022516491645101375\n",
      "Iteration:  9400 \ts:12.2401 \tAverage Loss:  0.014006136880137276\n",
      "Iteration:  9450 \ts:12.5117 \tAverage Loss:  0.017757292713122794\n",
      "Iteration:  9500 \ts:12.5105 \tAverage Loss:  0.016690018540236586\n",
      "Iteration:  9550 \ts:12.3266 \tAverage Loss:  0.012639456210633213\n",
      "Iteration:  9600 \ts:12.2913 \tAverage Loss:  0.010337617879443642\n",
      "Iteration:  9650 \ts:12.9261 \tAverage Loss:  0.017779894712984613\n",
      "Iteration:  9700 \ts:12.3596 \tAverage Loss:  0.022454584135497627\n",
      "Iteration:  9750 \ts:12.0440 \tAverage Loss:  0.0126744173847246\n",
      "Iteration:  9800 \ts:12.4792 \tAverage Loss:  0.026215487836481585\n",
      "Iteration:  9850 \ts:13.3225 \tAverage Loss:  0.02101204990235104\n",
      "Iteration:  9900 \ts:11.9269 \tAverage Loss:  0.021754655725753302\n",
      "Iteration:  9950 \ts:12.6319 \tAverage Loss:  0.01908314788045459\n",
      "Epoch time:  315.0378499031067\n",
      "Epoch 9\n",
      "Iteration:  10000 \ts:12.0330 \tAverage Loss:  0.0073090046521701165\n",
      "Iteration:  10050 \ts:12.8045 \tAverage Loss:  0.01609583612126915\n",
      "Iteration:  10100 \ts:12.5036 \tAverage Loss:  0.011240634174222918\n",
      "Iteration:  10150 \ts:12.8730 \tAverage Loss:  0.007977804957616819\n",
      "Iteration:  10200 \ts:13.6622 \tAverage Loss:  0.01588702578252299\n",
      "Iteration:  10250 \ts:12.2983 \tAverage Loss:  0.014859882136195707\n",
      "Iteration:  10300 \ts:13.8064 \tAverage Loss:  0.014759532466447248\n",
      "Iteration:  10350 \ts:15.1889 \tAverage Loss:  0.02295297208619367\n",
      "Iteration:  10400 \ts:16.1728 \tAverage Loss:  0.02058741081589048\n",
      "Iteration:  10450 \ts:17.2591 \tAverage Loss:  0.012647072749013367\n",
      "Iteration:  10500 \ts:16.7868 \tAverage Loss:  0.00862461632738416\n",
      "Iteration:  10550 \ts:14.8237 \tAverage Loss:  0.005864369111448404\n",
      "Iteration:  10600 \ts:13.2037 \tAverage Loss:  0.010629642724795297\n",
      "Iteration:  10650 \ts:15.6607 \tAverage Loss:  0.011958817291163158\n",
      "Iteration:  10700 \ts:16.0219 \tAverage Loss:  0.028059365627499878\n",
      "Iteration:  10750 \ts:12.8648 \tAverage Loss:  0.02843370779240793\n",
      "Iteration:  10800 \ts:12.0305 \tAverage Loss:  0.007291834165482101\n",
      "Iteration:  10850 \ts:12.3811 \tAverage Loss:  0.014241896597613568\n",
      "Iteration:  10900 \ts:13.2630 \tAverage Loss:  0.020193826114761677\n",
      "Iteration:  10950 \ts:18.0090 \tAverage Loss:  0.02540622630893772\n",
      "Iteration:  11000 \ts:12.8304 \tAverage Loss:  0.017579933535301927\n",
      "Iteration:  11050 \ts:12.3563 \tAverage Loss:  0.015721400932884214\n",
      "Iteration:  11100 \ts:12.2784 \tAverage Loss:  0.016458715021625638\n",
      "Iteration:  11150 \ts:8.4551 \tAverage Loss:  0.027860307094494524\n",
      "Iteration:  11200 \ts:9.6657 \tAverage Loss:  0.01783787197029529\n",
      "Epoch time:  337.8011248111725\n",
      "Epoch 10\n",
      "Iteration:  11250 \ts:11.9107 \tAverage Loss:  0.01154295546979519\n",
      "Iteration:  11300 \ts:12.0326 \tAverage Loss:  0.004680732475779195\n",
      "Iteration:  11350 \ts:14.3539 \tAverage Loss:  0.007854722614823437\n",
      "Iteration:  11400 \ts:11.7170 \tAverage Loss:  0.01120813087780654\n",
      "Iteration:  11450 \ts:11.8150 \tAverage Loss:  0.009251287974738034\n",
      "Iteration:  11500 \ts:11.0541 \tAverage Loss:  0.018580182771877424\n",
      "Iteration:  11550 \ts:12.2787 \tAverage Loss:  0.013409563822896865\n",
      "Iteration:  11600 \ts:12.3728 \tAverage Loss:  0.009652018675619373\n",
      "Iteration:  11650 \ts:13.8057 \tAverage Loss:  0.012413492455552238\n",
      "Iteration:  11700 \ts:12.8415 \tAverage Loss:  0.0166876885263715\n",
      "Iteration:  11750 \ts:11.6521 \tAverage Loss:  0.006974228631253645\n",
      "Iteration:  11800 \ts:11.4447 \tAverage Loss:  0.0041557298881132\n",
      "Iteration:  11850 \ts:11.9693 \tAverage Loss:  0.012680376172532738\n",
      "Iteration:  11900 \ts:11.9988 \tAverage Loss:  0.018164402979716884\n",
      "Iteration:  11950 \ts:11.9758 \tAverage Loss:  0.014561233488462442\n",
      "Iteration:  12000 \ts:12.2168 \tAverage Loss:  0.02556866777618989\n",
      "Iteration:  12050 \ts:12.8203 \tAverage Loss:  0.016546517842526923\n",
      "Iteration:  12100 \ts:11.8070 \tAverage Loss:  0.01900801274153803\n",
      "Iteration:  12150 \ts:11.5653 \tAverage Loss:  0.0310764957707406\n",
      "Iteration:  12200 \ts:11.8807 \tAverage Loss:  0.004154616810083347\n",
      "Iteration:  12250 \ts:12.1082 \tAverage Loss:  0.008975735155011044\n",
      "Iteration:  12300 \ts:11.6687 \tAverage Loss:  0.01111464570733272\n",
      "Iteration:  12350 \ts:12.0641 \tAverage Loss:  0.021986529653309324\n",
      "Iteration:  12400 \ts:11.7148 \tAverage Loss:  0.011350373194793874\n",
      "Iteration:  12450 \ts:12.2145 \tAverage Loss:  0.014562616264482315\n",
      "Epoch time:  302.3656213283539\n",
      "         \t \t    \tActual\t   \n",
      "         \t \t   0\t     2\t  1\n",
      "Predicted\t0\t6274\t    18\t 10\n",
      "         \t2\t  15\t   338\t  8\n",
      "         \t1\t  10\t     8\t784\n",
      "Accuracy:  0.9907568653717348\n",
      "Accuracy 0.9907568653717348\n",
      "Counter({35: 16, 13: 10, 3: 8, 47: 4, 23: 4, 41: 3, 34: 3, 44: 2, 15: 2, 46: 2, 33: 2, 16: 1, 1: 1, 17: 1, 4: 1, 43: 1, 29: 1, 49: 1, 19: 1, 18: 1, 7: 1, 24: 1, 27: 1, 31: 1})\n"
     ]
    }
   ],
   "source": [
    "for query in QUERY_NAMES[1:2]:\n",
    "    labels = QUERY_TO_LABELS[query]\n",
    "    dataset = BinaryTargetDataset(data, labels, binary_vectors) # here change labels\n",
    "    # We pass full dataset to the interface\n",
    "    interface = BinaryTargetInterface(dataset)\n",
    "\n",
    "    # Create datasets using the full dataset but with specific sample indices\n",
    "    # HERE CHANGE FUNCTION\n",
    "    train_set = AnimalCategorizer(\n",
    "        dataset_name=dataset,  # Pass the full dataset\n",
    "        function_name=query,\n",
    "        seed=42,\n",
    "        sample_indices=train_indices  # Pass only the sample indices you want\n",
    "    )\n",
    "    test_set = AnimalCategorizer(\n",
    "        dataset_name=dataset,\n",
    "        function_name=query,\n",
    "        seed=42,\n",
    "        sample_indices=test_indices\n",
    "    )\n",
    "\n",
    "    networks = {}\n",
    "    for i in QUERY_TO_INDICES[query]:\n",
    "        network = OptimizedMLP()\n",
    "        net = Network(network, f\"net{i}\", batching=True)\n",
    "        net.optimizer = torch.optim.AdamW(network.parameters(), lr=1e-4)\n",
    "        networks[f\"net{i}\"] = net\n",
    "    model = Model(QUERY_TO_KB[query], list(networks.values()))\n",
    "    model.set_engine(ExactEngine(model), cache=True)\n",
    "    # Add tensor sources for accessing the images\n",
    "    model.add_tensor_source(\"dataset\", interface)\n",
    "    # Create a data loader for training\n",
    "    loader = DataLoader(train_set, 24, shuffle=True)\n",
    "    # Train the model\n",
    "    train = train_model(model, loader, 10, log_iter=50, profile=0)\n",
    "    # Save the trained model\n",
    "    model.save_state(f\"snapshot/scratch_model_{query}.pth\")\n",
    "    \n",
    "    _, errors_indices = get_confusion_matrix_and_errors(model, test_set, verbose=1)\n",
    "    miss_labels = [label_indices[x] for x in errors_indices]\n",
    "    print(Counter(miss_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22699c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching ACs\n",
      "         \t \tActual\t    \n",
      "         \t \t     0\t   1\n",
      "Predicted\t0\t  5018\t 154\n",
      "         \t1\t    90\t2203\n",
      "Accuracy:  0.9673141326188881\n",
      "Accuracy 0.9673141326188881\n",
      "Counter({33: 32, 45: 19, 29: 13, 32: 13, 1: 12, 43: 11, 9: 11, 35: 11, 2: 11, 23: 11, 40: 9, 7: 9, 3: 8, 5: 7, 34: 7, 15: 7, 6: 5, 46: 5, 47: 4, 25: 3, 41: 3, 36: 3, 39: 3, 48: 2, 31: 2, 44: 2, 42: 2, 10: 2, 16: 2, 4: 2, 14: 2, 22: 2, 24: 2, 17: 1, 13: 1, 11: 1, 0: 1, 21: 1, 49: 1, 27: 1})\n"
     ]
    }
   ],
   "source": [
    "for query in QUERY_NAMES[3:]:\n",
    "    labels = QUERY_TO_LABELS[query]\n",
    "    dataset = BinaryTargetDataset(data, labels, binary_vectors) # here change labels\n",
    "    # We pass full dataset to the interface\n",
    "    interface = BinaryTargetInterface(dataset)\n",
    "\n",
    "    # Create datasets using the full dataset but with specific sample indices\n",
    "    # HERE CHANGE FUNCTION\n",
    "    train_set = AnimalCategorizer(\n",
    "        dataset_name=dataset,  # Pass the full dataset\n",
    "        function_name=query,\n",
    "        seed=42,\n",
    "        sample_indices=train_indices  # Pass only the sample indices you want\n",
    "    )\n",
    "    test_set = AnimalCategorizer(\n",
    "        dataset_name=dataset,\n",
    "        function_name=query,\n",
    "        seed=42,\n",
    "        sample_indices=test_indices\n",
    "    )\n",
    "\n",
    "    networks = {}\n",
    "    for i in QUERY_TO_INDICES[query]:\n",
    "        network = OptimizedMLP()\n",
    "        net = Network(network, f\"net{i}\", batching=True)\n",
    "        net.optimizer = torch.optim.AdamW(network.parameters(), lr=1e-4)\n",
    "        networks[f\"net{i}\"] = net\n",
    "    model = Model(QUERY_TO_KB[query], list(networks.values()))\n",
    "    model.load_state('snapshot/scratch_model_is_carnivore.pth')\n",
    "    model.set_engine(ExactEngine(model), cache=True)\n",
    "    # Add tensor sources for accessing the images\n",
    "    model.add_tensor_source(\"dataset\", interface)\n",
    "    \n",
    "    _, errors_indices = get_confusion_matrix_and_errors(model, test_set, verbose=1)\n",
    "    miss_labels = [label_indices[x] for x in errors_indices]\n",
    "    print(Counter(miss_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
